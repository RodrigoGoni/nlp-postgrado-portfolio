# ğŸ“ GuÃ­a de PresentaciÃ³n para Profesores

## ğŸ“‹ Resumen Ejecutivo

Este portfolio demuestra dominio completo de tÃ©cnicas de **Procesamiento de Lenguaje Natural**, desde mÃ©todos clÃ¡sicos hasta arquitecturas neuronales avanzadas, con implementaciones funcionales y resultados medibles en cada desafÃ­o.

---

## ğŸ¯ Competencias Demostradas

### 1ï¸âƒ£ Fundamentos de NLP ClÃ¡sico
- âœ… VectorizaciÃ³n de texto (TF-IDF, Bag of Words)
- âœ… ClasificaciÃ³n supervisada (NaÃ¯ve Bayes optimizado)
- âœ… MÃ©tricas de evaluaciÃ³n (F1-Score, Precision, Recall)
- âœ… AnÃ¡lisis de co-ocurrencia y similaridad

### 2ï¸âƒ£ Word Embeddings
- âœ… Entrenamiento de Word2Vec desde cero
- âœ… Preprocesamiento de corpus (tokenizaciÃ³n, limpieza)
- âœ… AnÃ¡lisis de espacios semÃ¡nticos
- âœ… VisualizaciÃ³n de embeddings (t-SNE, PCA)

### 3ï¸âƒ£ Redes Neuronales Recurrentes
- âœ… ImplementaciÃ³n de RNN, LSTM, GRU
- âœ… Modelos de lenguaje a nivel de carÃ¡cter
- âœ… Estrategias de generaciÃ³n (Greedy, Beam Search, Sampling)
- âœ… TÃ©cnicas anti-overfitting (Early Stopping, Dropout, L2)

### 4ï¸âƒ£ Arquitecturas Seq2Seq
- âœ… Encoder-Decoder con LSTM
- âœ… Transfer learning con embeddings pre-entrenados (GloVe)
- âœ… OptimizaciÃ³n de hiperparÃ¡metros basada en datos
- âœ… TraducciÃ³n automÃ¡tica (inglÃ©sâ†’espaÃ±ol)

---

## ğŸ“Š Resultados Cuantificables

| DesafÃ­o | MÃ©trica Principal | Resultado | Estado |
|---------|------------------|-----------|--------|
| 1 - Bag of Words | F1-Score (ComplementNB) | **0.6950** | âœ… SuperÃ³ baseline |
| 2 - Embeddings | Coherencia semÃ¡ntica | **Alta** | âœ… AnalogÃ­as vÃ¡lidas |
| 3 - LSTM | Perplexity / Accuracy | **3.51 / 0.60** | âœ… GeneraciÃ³n coherente |
| 4 - Seq2Seq | Convergencia | **Early stop aplicado** | âœ… Modelo funcional |

---

## ğŸ› ï¸ Stack TecnolÃ³gico

### Frameworks & Libraries
- **Deep Learning**: PyTorch, TensorFlow/Keras
- **NLP**: Gensim, NLTK, SpaCy
- **ML ClÃ¡sico**: scikit-learn
- **VisualizaciÃ³n**: Matplotlib, Seaborn
- **GestiÃ³n**: Git, Git LFS, Jupyter

### Buenas PrÃ¡cticas Aplicadas
- âœ… Control de versiones con Git (submÃ³dulos)
- âœ… DocumentaciÃ³n completa (READMEs detallados)
- âœ… CÃ³digo modular y reutilizable
- âœ… GestiÃ³n de archivos grandes (Git LFS)
- âœ… Reproducibilidad (requirements.txt, seeds aleatorias)

---

## ğŸ” NavegaciÃ³n del Portfolio

### Repositorio Principal
https://github.com/RodrigoGoni/nlp-postgrado-portfolio

### Repositorios Individuales (SubmÃ³dulos)

1. **DesafÃ­o 1**: https://github.com/RodrigoGoni/bag-of-words-npl
   - Notebook: `main.ipynb`
   - TÃ©cnicas: TF-IDF, NaÃ¯ve Bayes, similaridad

2. **DesafÃ­o 2**: https://github.com/RodrigoGoni/customs_embeddings
   - Notebook: `main.ipynb`
   - TÃ©cnicas: Word2Vec, embeddings personalizados

3. **DesafÃ­o 3**: https://github.com/RodrigoGoni/chatbot
   - Notebook: `desafio3.ipynb`
   - TÃ©cnicas: RNN/LSTM/GRU, generaciÃ³n de texto

4. **DesafÃ­o 4**: https://github.com/RodrigoGoni/seq2seq-translator
   - Notebook: `traductor_simplificado.ipynb`
   - TÃ©cnicas: Encoder-Decoder, GloVe, traducciÃ³n

---

## ğŸ’¡ Aspectos Destacados

### Originalidad
- **Datasets personalizados** en DesafÃ­o 2 (letras de canciones)
- **OptimizaciÃ³n inteligente** en DesafÃ­o 4 (hiperparÃ¡metros basados en P98)
- **AnÃ¡lisis lingÃ¼Ã­stico** en DesafÃ­o 3 (evaluaciÃ³n con SpaCy)

### Complejidad TÃ©cnica
- **~4.9M parÃ¡metros entrenables** en Seq2Seq (DesafÃ­o 4)
- **Corpus de 7.5M caracteres** procesado (DesafÃ­o 3)
- **118K pares de oraciones** para traducciÃ³n (DesafÃ­o 4)

### DocumentaciÃ³n
- **4 READMEs detallados** (uno por desafÃ­o)
- **1 README principal** unificado
- **GuÃ­as de instalaciÃ³n** paso a paso
- **MÃ©tricas y resultados** claramente presentados

---

## ğŸš€ EjecuciÃ³n RÃ¡pida (Para RevisiÃ³n)

```bash
# Clonar portfolio completo
git clone --recurse-submodules https://github.com/RodrigoGoni/nlp-postgrado-portfolio.git
cd nlp-postgrado-portfolio

# Instalar dependencias (opciÃ³n rÃ¡pida)
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate
chmod +x setup.sh && ./setup.sh

# Abrir notebooks
jupyter notebook
```

### Notebooks Clave para RevisiÃ³n

1. **DesafÃ­o 1**: `desafio1-bag-of-words/main.ipynb` â†’ TF-IDF y clasificaciÃ³n
2. **DesafÃ­o 2**: `desafio2-custom-embeddings/main.ipynb` â†’ Word2Vec custom
3. **DesafÃ­o 3**: `desafio3-chatbot/desafio3.ipynb` â†’ LSTM generativo
4. **DesafÃ­o 4**: `desafio4-seq2seq-translator/traductor_simplificado.ipynb` â†’ Traductor

**Tiempo estimado de revisiÃ³n**: 15-20 minutos por desafÃ­o (notebooks pre-ejecutados)

---

## ğŸ“ˆ ProgresiÃ³n PedagÃ³gica

El portfolio sigue una progresiÃ³n lÃ³gica de complejidad:

```
Fundamentos ClÃ¡sicos â†’ Embeddings â†’ RNNs â†’ Seq2Seq
     (DesafÃ­o 1)    â†’  (DesafÃ­o 2) â†’ (DesafÃ­o 3) â†’ (DesafÃ­o 4)
```

### Conexiones Entre DesafÃ­os

- **1â†’2**: De vectores dispersos (TF-IDF) a vectores densos (embeddings)
- **2â†’3**: De embeddings estÃ¡ticos a representaciones contextuales (RNN)
- **3â†’4**: De modelado de lenguaje a traducciÃ³n (secuencia a secuencia)

---

## ğŸ“ ReflexiÃ³n CrÃ­tica

### Fortalezas
- âœ… Implementaciones completas y funcionales
- âœ… ExperimentaciÃ³n con mÃºltiples arquitecturas
- âœ… AnÃ¡lisis cuantitativo de resultados
- âœ… CÃ³digo limpio y bien documentado

### Ãreas de Mejora Futuras
- ğŸ”„ Implementar mecanismo de atenciÃ³n en Seq2Seq
- ğŸ”„ Explorar Transformers (BERT, GPT)
- ğŸ”„ Fine-tuning de modelos pre-entrenados
- ğŸ”„ Despliegue en producciÃ³n (API REST)

---

## ğŸ“ Contacto

**Rodrigo GoÃ±i**  
ğŸ“§ Email: [tu-email]  
ğŸ”— GitHub: [@RodrigoGoni](https://github.com/RodrigoGoni)

---

## âœ… Checklist de EvaluaciÃ³n

Para facilitar la revisiÃ³n, los desafÃ­os cumplen con:

- [x] ImplementaciÃ³n completa y funcional
- [x] CÃ³digo ejecutable sin errores
- [x] DocumentaciÃ³n clara (README + comentarios)
- [x] Resultados cuantitativos reportados
- [x] Buenas prÃ¡cticas de ingenierÃ­a de software
- [x] Reproducibilidad (requirements.txt, seeds)
- [x] Visualizaciones de resultados
- [x] AnÃ¡lisis de mÃ©tricas de evaluaciÃ³n

---

**Nota**: Todos los notebooks estÃ¡n pre-ejecutados con outputs guardados para facilitar la revisiÃ³n sin necesidad de re-entrenar modelos (lo cual puede tomar horas).

---

<div align="center">

### ğŸ“ Portfolio desarrollado para el Programa de Postgrado en NLP

**Diciembre 2025**

</div>
